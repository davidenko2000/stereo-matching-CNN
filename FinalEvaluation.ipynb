{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidenko2000/stereo-matching-CNN/blob/main/FinalEvaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "l0sU79AfR3V0",
        "outputId": "7417071e-b45c-44db-9af1-fe494ca1be17"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-caa85e88d349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgRr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \"\"\"\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2124\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2126\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2127\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m         }\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpil_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m              (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[1;32m    392\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             im, l, b, trans = self.make_image(\n\u001b[0;32m--> 626\u001b[0;31m                 renderer, renderer.get_image_magnification())\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mmake_image\u001b[0;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_bbox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             magnification, unsampled=unsampled)\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_unsampled_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_make_image\u001b[0;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_scalar_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 output_alpha = _resample(  # resample alpha channel\n\u001b[0;32m--> 522\u001b[0;31m                     self, A[..., 3], out_shape, t, alpha=alpha)\n\u001b[0m\u001b[1;32m    523\u001b[0m                 output = _resample(  # resample rgb channels\n\u001b[1;32m    524\u001b[0m                     self, _rgb_to_rgba(A[..., :3]), out_shape, t, alpha=alpha)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_resample\u001b[0;34m(image_obj, data, out_shape, transform, resample, alpha)\u001b[0m\n\u001b[1;32m    200\u001b[0m                     \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mimage_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_filternorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                     image_obj.get_filterrad())\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "imgLr = plt.imread('drive/MyDrive/data_scene_flow/RGB/left/000000_10.png')\n",
        "imgRr = plt.imread('drive/MyDrive/data_scene_flow/RGB/right/000000_10.png')\n",
        "f = plt.figure(figsize=(100,100),dpi=80)\n",
        "f.add_subplot(1,2, 1)\n",
        "plt.imshow(imgLr)\n",
        "f.add_subplot(1,2, 2)\n",
        "plt.imshow(imgRr)\n",
        "plt.show(block=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khAnfScX7vPF",
        "outputId": "366c8f45-b025-436e-a47b-2275c5f9ca8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat May 21 20:21:10 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd-auBysGMjU",
        "outputId": "22b3568f-83a7-4a17-b537-6ce770427081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QHJygVNFSw7y"
      },
      "outputs": [],
      "source": [
        "PATCH_SIZE = 9\n",
        "MAX_DISP = 229\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "PIXEL_ERROR = 3\n",
        "\n",
        "LR = 0.001\n",
        "LR_CHANGE_AT_EPOCH = 10\n",
        "LR_AFTER_10_EPOCHS = 0.0001\n",
        "\n",
        "\n",
        "FEATURES = 64\n",
        "MARGIN = 0.2\n",
        "EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V5ij5W3fSo8K"
      },
      "outputs": [],
      "source": [
        "IMAGES_DIR = 'drive/MyDrive/data_scene_flow/'\n",
        "\n",
        "DISP_DIR = IMAGES_DIR + 'disparity/'\n",
        "RGB_DIR = IMAGES_DIR + 'RGB/'\n",
        "GRAY_DIR = IMAGES_DIR + 'GRAY/'\n",
        "\n",
        "RGB_LEFT_DIR = RGB_DIR + 'left/'\n",
        "RGB_RIGHT_DIR = RGB_DIR + 'right/'\n",
        "GRAY_LEFT_DIR = GRAY_DIR + 'left/'\n",
        "GRAY_RIGHT_DIR = GRAY_DIR + 'right/'\n",
        "\n",
        "IS_GRAY = False\n",
        "\n",
        "PATCH_SIZE = 9\n",
        "MAX_DISPARITY = 229 #povecat mozda\n",
        "\n",
        "NUM_IMAGES = 200\n",
        "TRAIN_START = 0\n",
        "TRAIN_END = 160\n",
        "VALID_START = 160\n",
        "VALID_END = 200\n",
        "\n",
        "TRAIN_DATA = IMAGES_DIR + 'train/'\n",
        "VALID_DATA = IMAGES_DIR + 'valid/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "r8Yhx7tmSpgn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import skimage\n",
        "import torch\n",
        "from matplotlib import image as mpimg\n",
        "from torch import nn\n",
        "import torchvision.datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "#Method returns a filename which is made of prefix, which length is 6\n",
        "def get_filename(idx):\n",
        "      return str.zfill(str(idx), 6) + \"_10.png\"\n",
        "\n",
        "# Method returns an disparity image at index (HxW)\n",
        "def get_disp_image(idx):\n",
        "      return skimage.util.img_as_ubyte(mpimg.imread(DISP_DIR + get_filename(idx)))\n",
        "\n",
        "# Method returns an image at index (HxWxC)\n",
        "def get_image(idx, is_left):\n",
        "    \treturn mpimg.imread((GRAY_LEFT_DIR if IS_GRAY else RGB_LEFT_DIR) + get_filename(idx)) if is_left else mpimg.imread((GRAY_RIGHT_DIR if IS_GRAY else RGB_RIGHT_DIR) + get_filename(idx))\n",
        "\n",
        "#Method which computes mean and standard deviation, used for normalization\n",
        "def get_mean_std():\n",
        "      RGB_transform = transforms.Compose([\n",
        "              transforms.Resize(256),\n",
        "              transforms.CenterCrop(256),\n",
        "              transforms.ToTensor()\n",
        "          ])\n",
        "      GRAY_transform = transforms.Compose([\n",
        "          transforms.Resize(256),\n",
        "          transforms.CenterCrop(256),\n",
        "          transforms.Grayscale(),\n",
        "          transforms.ToTensor()\n",
        "      ])\n",
        "\n",
        "      images_data = torchvision.datasets.ImageFolder(root=(GRAY_DIR if IS_GRAY else RGB_DIR),\n",
        "                transform=(GRAY_transform if IS_GRAY else RGB_transform))\n",
        "      data_loader = DataLoader(images_data, batch_size=len(images_data), shuffle=False, num_workers=0)\n",
        "      images, _ = next(iter(data_loader))\n",
        "      mean, std = images.mean([0, 2, 3]), images.std([0, 2, 3])\n",
        "      return mean, std\n",
        "\n",
        "#Method returns disparity file, which consists of narrays\n",
        "def load_disparity_data(train=True):\n",
        "    \treturn np.load((TRAIN_DATA if train else VALID_DATA) + 'disparities.npy')\n",
        "\n",
        "#Method which converts RGB images to grayscale\n",
        "def convert_to_grayscale():\n",
        "      for idx in range(NUM_IMAGES):\n",
        "            filename = get_filename(idx)\n",
        "            Image.open(RGB_LEFT_DIR + filename).convert(\"L\").save(GRAY_LEFT_DIR + filename)\n",
        "            Image.open(RGB_RIGHT_DIR + filename).convert(\"L\").save(GRAY_RIGHT_DIR + filename)\n",
        "\n",
        "#Method which makes narrays and saves disparity data to file\n",
        "def make_disparity_data(train=True):\n",
        "      \n",
        "      def filter(idx):\n",
        "              distance = PATCH_SIZE // 2\n",
        "              disp_image = get_disp_image(idx)\n",
        "              rows, cols = disp_image.nonzero() #returns non zero pixels (pixels with known disparity)\n",
        "              rows = rows.astype(np.uint16)\n",
        "              cols = cols.astype(np.uint16) \n",
        "              disparity_values = disp_image[rows, cols]\n",
        "              \n",
        "              pos_cols = cols - disparity_values #computes cols with correct disparity\n",
        "              neg_cols = pos_cols + np.random.choice([-8, -7, -6, -5, -4, 4, 5, 6, 7, 8], size=pos_cols.size).astype(np.uint16) #computes cols with incorrect disparity\n",
        "\n",
        "              #CFilters which will be used to discard changes to a pixel which are not allowed\n",
        "              filterR = (rows >= distance) & (rows < disp_image.shape[0] - distance)\n",
        "              filterC = (cols >= distance) & (cols < disp_image.shape[1] - distance)\n",
        "              filterPC = (pos_cols >= distance) & (pos_cols < disp_image.shape[1] - distance)\n",
        "              filterNC = (neg_cols >= distance) & (neg_cols < disp_image.shape[1] - distance)\n",
        "\n",
        "              main_filter = filterR & filterC & filterPC & filterNC\n",
        "              #Making narray of image indexes and corresponding rows, cols, pos_cols and neg_cols\n",
        "              newR = rows[main_filter]\n",
        "              newC = cols[main_filter]\n",
        "              newPC = pos_cols[main_filter]\n",
        "              newNC = neg_cols[main_filter]\n",
        "              \n",
        "              result = np.empty(len(newR), dtype=np.dtype([('idx', 'uint8'), ('row', 'uint16'), ('col', 'uint16'), ('col_pos', 'uint16'), ('col_neg', 'uint16'), ]))\n",
        "              result['idx'] = np.full(newR.shape, idx, dtype=np.uint8)\n",
        "              result['row'] = newR\n",
        "              result['col'] = newC\n",
        "              result['col_pos'] = newPC\n",
        "              result['col_neg'] = newNC\n",
        "\n",
        "              return result\n",
        "\n",
        "      disparities = np.concatenate([filter(idx) for idx in range(TRAIN_START if train else VALID_START, TRAIN_END if train else VALID_END)])\n",
        "      np.save((TRAIN_DATA if train else VALID_DATA) + 'disparities.npy', disparities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7jTfkgymi5a3"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class StereoCNN(nn.Module):\n",
        "\tdef __init__(self, in_channels=3, features=64, ksize=3, padding=1):\n",
        "          super().__init__()\n",
        "          self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=features, kernel_size=ksize, padding=padding)\n",
        "          self.conv2 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=ksize, padding=padding)\n",
        "          self.conv3 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=ksize, padding=padding)\n",
        "          self.conv4 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=ksize, padding=padding)\n",
        "\tdef forward(self, x):\n",
        "          x = F.relu(self.conv1(x))\n",
        "          x = F.relu(self.conv2(x))\n",
        "          x = F.relu(self.conv3(x))\n",
        "          x = self.conv4(x)\n",
        "          x = x.squeeze(3).squeeze(2) \n",
        "          return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "atuucoSLPIiC"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class StereoCNN_BN(nn.Module):\n",
        "\tdef __init__(self, in_channels=3, features=64, ksize=3, padding=1):\n",
        "          super().__init__()\n",
        "          self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=features, kernel_size=ksize, padding=padding)\n",
        "          self.bn1 = nn.BatchNorm2d(features)\n",
        "          self.conv2 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=ksize, padding=padding)\n",
        "          self.bn2 = nn.BatchNorm2d(features)\n",
        "          self.conv3 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=ksize, padding=padding)\n",
        "          self.bn3 = nn.BatchNorm2d(features)\n",
        "          self.conv4 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=ksize, padding=padding)\n",
        "          self.bn4 = nn.BatchNorm2d(features)\n",
        "\tdef forward(self, x):\n",
        "          x = F.relu(self.bn1(self.conv1(x)))\n",
        "          x = F.relu(self.bn2(self.conv2(x)))\n",
        "          x = F.relu(self.bn3(self.conv3(x)))\n",
        "          x = self.bn4(self.conv4(x))\n",
        "          x = x.squeeze(3).squeeze(2)\n",
        "          return  F.normalize(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SZ614mlrSRyR"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class PatchesExtractor(Dataset):\n",
        "\n",
        "  def __init__(self, tform, train=True):\n",
        "          self.transform = tform\n",
        "          self.disparity_data = load_disparity_data(train=train)\n",
        "          self.len = self.disparity_data.size\n",
        "          self.left_images = {}\n",
        "          self.right_images = {}\n",
        "          \n",
        "          for idx in range(TRAIN_START if train else VALID_START, TRAIN_END if train else VALID_END):\n",
        "                        self.left_images[idx] = get_image(idx, is_left=True)\n",
        "                        self.right_images[idx] = get_image(idx, is_left=False)\n",
        "\t#Method that extracts patches from particular image\n",
        "  def __getitem__(self, patch_idx):\n",
        "          patch_data = self.disparity_data[patch_idx]\n",
        "          image_idx = patch_data['idx']\n",
        "          row = patch_data['row']\n",
        "          col = patch_data['col']\n",
        "          col_pos = patch_data['col_pos']\n",
        "          col_neg = patch_data['col_neg']\n",
        "\n",
        "          patch_size = PATCH_SIZE\n",
        "          left_image = self.left_images[image_idx]\n",
        "          right_pos_image = self.right_images[image_idx]\n",
        "          rigth_neg_image = self.right_images[image_idx]\n",
        "\n",
        "          if self.transform:\n",
        "              left_patch = self.transform(left_image[(row - patch_size // 2):(row + patch_size//2 + 1 ), (col - patch_size // 2):(col + patch_size//2 + 1)])\n",
        "              right_positive_patch = self.transform(right_pos_image[(row - patch_size // 2):(row + patch_size//2 + 1 ), (col_pos - patch_size // 2):(col_pos + patch_size//2 + 1)])\n",
        "              right_negative_patch = self.transform(rigth_neg_image[(row - patch_size // 2):(row + patch_size//2 + 1 ), (col_neg - patch_size // 2):(col_neg + patch_size//2 + 1)])\n",
        "                                                    \n",
        "          return left_patch, right_positive_patch, right_negative_patch\n",
        "  def __len__(self):\n",
        "    return self.len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzbX6dvYbtwM"
      },
      "outputs": [],
      "source": [
        "make_disparity_data(train=True)\n",
        "make_disparity_data(train=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ARCPQO96dM2"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "\n",
        "model = StereoCNN(in_channels=3)\n",
        "model.to(device)\n",
        "\n",
        "RGB_transform = transforms.Compose([\n",
        "\ttransforms.ToTensor(),\n",
        "\ttransforms.Normalize((0.4817, 0.5085, 0.5006), (0.3107, 0.3249, 0.3350))\n",
        "\t])\n",
        "GRAY_transform = transforms.Compose([\n",
        "\ttransforms.ToTensor(),\n",
        "    \ttransforms.Normalize((0.4999), (0.3180))\n",
        "\t])\n",
        "\n",
        "train_dataset = PatchesExtractor(tform=RGB_transform,train=True)\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, \n",
        "                             shuffle=True, num_workers=4)\n",
        "\n",
        "valid_dataset = PatchesExtractor(tform=RGB_transform, train=False)\n",
        "valid_loader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, num_workers=4)\n",
        "    \n",
        "criterion = nn.TripletMarginLoss(margin=MARGIN)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LR)\n",
        "\n",
        "train_report = np.zeros((EPOCHS, ))\n",
        "valid_report = np.zeros((EPOCHS, ))\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    print('\\nTraining epoch: %d' % epoch)\n",
        "    train_loss = 0\n",
        "    epoch_batches = 0\n",
        "    model.train()\n",
        "    for left_patch, right_pos_patch, right_neg_patch in train_dataloader:\n",
        "      epoch_batches += 1\n",
        "      left_patch, right_pos_patch, right_neg_patch = left_patch.to(device), right_pos_patch.to(device), right_neg_patch.to(device)\n",
        "      left_output, right_pos_output, right_neg_output = model(left_patch), model(right_pos_patch), model(right_neg_patch)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss = criterion(left_output, right_pos_output, right_neg_output)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss += loss.item()\n",
        "      if epoch_batches % 15000 == 0:\n",
        "         print('Train -> Loss: %.3f \\n' % (train_loss/ epoch_batches))\n",
        "    \n",
        "    train_report[epoch] = train_loss / epoch_batches\n",
        "    #torch.save(model, TRAIN_DATA + f\"train_model_BNGRAY_{epoch}.pth\")\n",
        "\n",
        "def valid(epoch):\n",
        "    print('\\nValidation epoch: %d' % epoch)\n",
        "    valid_loss = 0\n",
        "    epoch_batches = 0\n",
        "    model.eval()\n",
        "    for left_patch, right_pos_patch, right_neg_patch in valid_loader:\n",
        "      epoch_batches += 1\n",
        "      left_patch, right_pos_patch, right_neg_patch = left_patch.to(device), right_pos_patch.to(device), right_neg_patch.to(device)\n",
        "      left_output, right_pos_output, right_neg_output = model(left_patch), model(right_pos_patch), model(right_neg_patch)\n",
        "\n",
        "      loss = criterion(left_output, right_pos_output, right_neg_output)\n",
        "      valid_loss += loss.item()\n",
        "\n",
        "    print('Valid -> Loss: %.3f \\n' % (valid_loss/ epoch_batches))\n",
        "    valid_report[epoch] = valid_loss / epoch_batches\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    if epoch == LR_CHANGE_AT_EPOCH:\n",
        "            for param in optimizer.param_groups:\n",
        "                  param['lr'] = LR_AFTER_10_EPOCHS\n",
        "    train(epoch)\n",
        "    #valid(epoch)\n",
        "\n",
        "#np.save(TRAIN_DATA + 'training_report_BNGRAY.npy', train_report)\n",
        "#np.save(VALID_DATA + 'validation_report_GRAY.npy', valid_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apd4V94EuTGN"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "RGB_transform = transforms.Compose([\n",
        "\ttransforms.ToTensor(),\n",
        "\ttransforms.Normalize((0.4817, 0.5085, 0.5006), (0.3107, 0.3249, 0.3350))\n",
        "\t])\n",
        "GRAY_transform = transforms.Compose([\n",
        "\ttransforms.ToTensor(),\n",
        "    \ttransforms.Normalize((0.4999), (0.3180))\n",
        "\t])\n",
        "valid_dataset = PatchesExtractor(tform=RGB_transform, train=False)\n",
        "valid_loader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, num_workers=4)\n",
        "    \n",
        "criterion = nn.TripletMarginLoss(margin=MARGIN)\n",
        "\n",
        "valid_report = np.zeros((EPOCHS, ))\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model = torch.load(TRAIN_DATA + f\"train_model_{epoch}.pth\")\n",
        "    model.eval()\n",
        "    print('\\nValidation epoch: %d' % epoch)\n",
        "    valid_loss = 0\n",
        "    epoch_batches = 0\n",
        "    for left_patch, right_pos_patch, right_neg_patch in valid_loader:\n",
        "      epoch_batches += 1\n",
        "      left_patch, right_pos_patch, right_neg_patch = left_patch.to(device), right_pos_patch.to(device), right_neg_patch.to(device)\n",
        "      left_output, right_pos_output, right_neg_output = model(left_patch), model(right_pos_patch), model(right_neg_patch)\n",
        "      \n",
        "      loss = criterion(left_output, right_pos_output, right_neg_output)\n",
        "      valid_loss += loss.item()\n",
        "\n",
        "    print('Valid -> Loss: %.3f \\n' % (valid_loss/ epoch_batches))\n",
        "    valid_report[epoch] = valid_loss / epoch_batches\n",
        "\n",
        "#np.save(VALID_DATA + 'validation_report_GRAY.npy', valid_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CK-OdTXmdStK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from matplotlib import pyplot as plt, colors\n",
        "from torchvision.transforms import ToTensor \n",
        "\n",
        "def plot_acc_byimage(idx, model):\n",
        "\treal_disp = get_disp_image(idx)\n",
        "\tpredicted_disp = compute_disparity_map(idx, model)\n",
        "\tacc = disparity_accuracy_byimage(real_disp=real_disp, predicted_disp=predicted_disp)\n",
        "\n",
        "\tplt.figure(figsize=(20, 10))\n",
        "\tcolor_map = colors.ListedColormap(['black', 'blue', 'green'])\n",
        "\tplt.imshow(acc, cmap=color_map)\n",
        " \n",
        "#Method which uses real disparity, predicted disparity and pixel error to calcuate accuracy of prediction.\n",
        "#Returns:\n",
        "#        -1 -> if the real disparity is unknown\n",
        "#        0  -> if the prediction in incorrect\n",
        "#        1  -> if the prediction is correct (the prediction must be in the interval which uses allowed pixel error\n",
        "#\n",
        "def disparity_accuracy_byimage(real_disp, predicted_disp, pxl_error=PIXEL_ERROR):\n",
        "\tacc = np.zeros(real_disp.shape)\n",
        "\tacc[real_disp == 0] = -1\n",
        "\tacc[(real_disp != 0) & (np.abs(predicted_disp - real_disp) < pxl_error)] = 1\n",
        "\n",
        "\treturn acc\n",
        "\n",
        "#Method which calculates accuracy percentage, by using real and predicted disparity.\n",
        "def compute_accuracy(model, train=True):\n",
        "\tcounter_correct = 0\n",
        "\tcounter_total = 0\n",
        "\tpxl_error=PIXEL_ERROR\n",
        "\tfor idx in range(TRAIN_START if train else VALID_START,TRAIN_END if train else VALID_END):\n",
        "\t\treal_disp = get_disp_image(idx)\n",
        "\t\tpredicted_disp = compute_disparity_map(idx, model)\n",
        "\t\tcounter_correct += np.count_nonzero((real_disp != 0) & (np.abs(predicted_disp - real_disp) < pxl_error))\n",
        "\t\tcounter_total += np.count_nonzero(real_disp)\n",
        "\n",
        "\treturn counter_correct / counter_total\n",
        "\n",
        "#Method which computes a disparity map of the left and right image\n",
        "def compute_disparity_map(idx, model):\n",
        "      max_disp = MAX_DISP\n",
        "      model.eval()\n",
        "\n",
        "      left_img = get_image(idx, is_left=True)\n",
        "      right_img = get_image(idx, is_left=False)\n",
        "\n",
        "      #Adding the padding, as a result the output image will have the same dimensions as input\n",
        "      padding = PATCH_SIZE // 2\n",
        "      left_pad = np.pad(left_img, ((padding, padding), (padding, padding), (0, 0)))\n",
        "      right_pad = np.pad(right_img, ((padding, padding), (padding, padding), (0, 0)))\n",
        "\n",
        "      left = ToTensor()(left_pad).unsqueeze(0)\n",
        "      right = ToTensor()(right_pad).unsqueeze(0)\n",
        "      left, right = left.to(device), right.to(device)\n",
        "      #Making a ndarray of the tensor, which is the output of the model\n",
        "      left_tensor = model(left)\n",
        "      right_tensor = model(right)\n",
        "\n",
        "      left_array = left_tensor.cpu().squeeze(0).permute(1, 2, 0).detach().numpy()\n",
        "      right_array = right_tensor.cpu().squeeze(0).permute(1, 2, 0).detach().numpy()\n",
        "\n",
        "      #ndarray[HxWxD]\n",
        "      stacked_disp =  np.stack([np.sum(left_array * np.roll(right_array, d, axis=1) , axis=2) for d in range(max_disp)], axis=2)\n",
        "      #ndarray[HxW]-using argmax to extract the most similar\n",
        "      disp_map =  np.argmax(stacked_disp, axis=2)\n",
        "\n",
        "      return disp_map\n",
        "\n",
        "def plot_images(model, idx):\n",
        "    real_disparity = get_disp_image(idx)\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.imshow(real_disparity)\n",
        "    plt.title(f'real disparity {idx}')\n",
        "    predicted_disparity = compute_disparity_map(idx, model)\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.imshow(predicted_disparity)\n",
        "    plt.title(f'predicted disparity {idx}')\n",
        "    plt.show()\n",
        "\n",
        "    plot_acc_byimage(idx, model)\n",
        "    plt.title(f\"accuracy image {idx}\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.imshow(get_image(idx, True))\n",
        "    plt.title(f\"left image {idx}\")\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.imshow(get_image(idx, False))\n",
        "    plt.title(f\"right image {idx}\")\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_model(model):\n",
        "    train_accuracy = compute_accuracy(model, train=True)\n",
        "    test_accuracy = compute_accuracy(model, train=False)\n",
        "    print(f\"train accuracy = {train_accuracy}\\ntest accuracy = {test_accuracy}\")\n",
        "\n",
        "model = torch.load(TRAIN_DATA + f\"train_model_{EPOCHS-1}.pth\")\n",
        "modelGRAY = torch.load(TRAIN_DATA + f\"train_modelGRAY_{EPOCHS-1}.pth\")\n",
        "device = 'cuda'\n",
        "model.to(device)\n",
        "\n",
        "img_idx = 187\n",
        "plot_images(model, img_idx)\n",
        "evaluate_model(model)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "StereoCNN.ipynb",
      "provenance": [],
      "mount_file_id": "1OVqTSOlQbfY7TP5TqC-FQgPNfNgB9ax6",
      "authorship_tag": "ABX9TyOU0ATMkrFueynJFL4jyxyf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}