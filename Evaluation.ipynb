{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidenko2000/stereo-matching-CNN/blob/main/Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khAnfScX7vPF"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHJygVNFSw7y"
      },
      "outputs": [],
      "source": [
        "PATCH_SIZE = 9\n",
        "MAX_DISP = 229\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "PIXEL_ERROR = 3\n",
        "\n",
        "LR = 0.001\n",
        "LR_CHANGE_AT_EPOCH = 10\n",
        "LR_AFTER_10_EPOCHS = 0.0001\n",
        "\n",
        "\n",
        "FEATURES = 64\n",
        "MARGIN = 0.2\n",
        "EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5ij5W3fSo8K"
      },
      "outputs": [],
      "source": [
        "IMAGES_DIR = 'drive/MyDrive/data_scene_flow/'\n",
        "\n",
        "DISP_DIR = IMAGES_DIR + 'disparity/'\n",
        "RGB_DIR = IMAGES_DIR + 'RGB/'\n",
        "GRAY_DIR = IMAGES_DIR + 'GRAY/'\n",
        "\n",
        "RGB_LEFT_DIR = RGB_DIR + 'left/'\n",
        "RGB_RIGHT_DIR = RGB_DIR + 'right/'\n",
        "GRAY_LEFT_DIR = GRAY_DIR + 'left/'\n",
        "GRAY_RIGHT_DIR = GRAY_DIR + 'right/'\n",
        "\n",
        "IS_GRAY = False\n",
        "\n",
        "PATCH_SIZE = 9\n",
        "MAX_DISPARITY = 229 \n",
        "\n",
        "NUM_IMAGES = 200\n",
        "TRAIN_START = 0\n",
        "TRAIN_END = 160\n",
        "VALID_START = 160\n",
        "VALID_END = 200\n",
        "\n",
        "TRAIN_DATA = IMAGES_DIR + 'train/'\n",
        "VALID_DATA = IMAGES_DIR + 'valid/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8Yhx7tmSpgn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import skimage\n",
        "import torch\n",
        "from matplotlib import image as mpimg\n",
        "from torch import nn\n",
        "import torchvision.datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "#Method returns a filename which is made of prefix, which length is 6\n",
        "def get_filename(idx):\n",
        "      return str.zfill(str(idx), 6) + \"_10.png\"\n",
        "\n",
        "# Method returns an disparity image at index (HxW)\n",
        "def get_disp_image(idx):\n",
        "      return skimage.util.img_as_ubyte(mpimg.imread(DISP_DIR + get_filename(idx)))\n",
        "\n",
        "# Method returns an image at index (HxWxC)\n",
        "def get_image(idx, is_left):\n",
        "    \treturn mpimg.imread((GRAY_LEFT_DIR if IS_GRAY else RGB_LEFT_DIR) + get_filename(idx)) if is_left else mpimg.imread((GRAY_RIGHT_DIR if IS_GRAY else RGB_RIGHT_DIR) + get_filename(idx))\n",
        "\n",
        "#Method which computes mean and standard deviation, used for normalization\n",
        "def get_mean_std():\n",
        "      RGB_transform = transforms.Compose([\n",
        "              transforms.Resize(256),\n",
        "              transforms.CenterCrop(256),\n",
        "              transforms.ToTensor()\n",
        "          ])\n",
        "      GRAY_transform = transforms.Compose([\n",
        "          transforms.Resize(256),\n",
        "          transforms.CenterCrop(256),\n",
        "          transforms.Grayscale(),\n",
        "          transforms.ToTensor()\n",
        "      ])\n",
        "\n",
        "      images_data = torchvision.datasets.ImageFolder(root=(GRAY_DIR if IS_GRAY else RGB_DIR),\n",
        "                transform=(GRAY_transform if IS_GRAY else RGB_transform))\n",
        "      data_loader = DataLoader(images_data, batch_size=len(images_data), shuffle=False, num_workers=0)\n",
        "      images, _ = next(iter(data_loader))\n",
        "      mean, std = images.mean([0, 2, 3]), images.std([0, 2, 3])\n",
        "      return mean, std\n",
        "\n",
        "#Method returns disparity file, which consists of narrays\n",
        "def load_disparity_data(train=True):\n",
        "    \treturn np.load((TRAIN_DATA if train else VALID_DATA) + 'disparities.npy')\n",
        "\n",
        "#Method which converts RGB images to grayscale\n",
        "def convert_to_grayscale():\n",
        "      for idx in range(NUM_IMAGES):\n",
        "            filename = get_filename(idx)\n",
        "            Image.open(RGB_LEFT_DIR + filename).convert(\"L\").save(GRAY_LEFT_DIR + filename)\n",
        "            Image.open(RGB_RIGHT_DIR + filename).convert(\"L\").save(GRAY_RIGHT_DIR + filename)\n",
        "\n",
        "#Method which makes narrays and saves disparity data to file\n",
        "def make_disparity_data(train=True):\n",
        "      \n",
        "      def filter(idx):\n",
        "              distance = PATCH_SIZE // 2\n",
        "              disp_image = get_disp_image(idx)\n",
        "              rows, cols = disp_image.nonzero() #returns non zero pixels (pixels with known disparity)\n",
        "              rows = rows.astype(np.uint16)\n",
        "              cols = cols.astype(np.uint16) \n",
        "              disparity_values = disp_image[rows, cols]\n",
        "              \n",
        "              pos_cols = cols - disparity_values #computes cols with correct disparity\n",
        "              neg_cols = pos_cols + np.random.choice([-8, -7, -6, -5, -4, 4, 5, 6, 7, 8], size=pos_cols.size).astype(np.uint16) #computes cols with incorrect disparity\n",
        "\n",
        "              #CFilters which will be used to discard changes to a pixel which are not allowed\n",
        "              filterR = (rows >= distance) & (rows < disp_image.shape[0] - distance)\n",
        "              filterC = (cols >= distance) & (cols < disp_image.shape[1] - distance)\n",
        "              filterPC = (pos_cols >= distance) & (pos_cols < disp_image.shape[1] - distance)\n",
        "              filterNC = (neg_cols >= distance) & (neg_cols < disp_image.shape[1] - distance)\n",
        "\n",
        "              main_filter = filterR & filterC & filterPC & filterNC\n",
        "              #Making narray of image indexes and corresponding rows, cols, pos_cols and neg_cols\n",
        "              newR = rows[main_filter]\n",
        "              newC = cols[main_filter]\n",
        "              newPC = pos_cols[main_filter]\n",
        "              newNC = neg_cols[main_filter]\n",
        "              \n",
        "              result = np.empty(len(newR), dtype=np.dtype([('idx', 'uint8'), ('row', 'uint16'), ('col', 'uint16'), ('col_pos', 'uint16'), ('col_neg', 'uint16'), ]))\n",
        "              result['idx'] = np.full(newR.shape, idx, dtype=np.uint8)\n",
        "              result['row'] = newR\n",
        "              result['col'] = newC\n",
        "              result['col_pos'] = newPC\n",
        "              result['col_neg'] = newNC\n",
        "\n",
        "              return result\n",
        "\n",
        "      disparities = np.concatenate([filter(idx) for idx in range(TRAIN_START if train else VALID_START, TRAIN_END if train else VALID_END)])\n",
        "      np.save((TRAIN_DATA if train else VALID_DATA) + 'disparities.npy', disparities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jTfkgymi5a3"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class StereoCNN(nn.Module):\n",
        "\tdef __init__(self, in_channels=3, features=64, ksize=3, padding=1):\n",
        "          super().__init__()\n",
        "          self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=features, kernel_size=ksize, padding=padding)\n",
        "          self.conv2 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=ksize, padding=padding)\n",
        "          self.conv3 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=ksize, padding=padding)\n",
        "          self.conv4 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=ksize, padding=padding)\n",
        "\tdef forward(self, x):\n",
        "          x = F.relu(self.conv1(x))\n",
        "          x = F.relu(self.conv2(x))\n",
        "          x = F.relu(self.conv3(x))\n",
        "          x = self.conv4(x)\n",
        "          x = x.squeeze(3).squeeze(2) \n",
        "          return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CK-OdTXmdStK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from matplotlib import pyplot as plt, colors\n",
        "from torchvision.transforms import ToTensor \n",
        "\n",
        "def plot_acc_byimage(idx, model):\n",
        "\treal_disp = get_disp_image(idx)\n",
        "\tpredicted_disp = compute_disparity_map(idx, model)\n",
        "\tacc = disparity_accuracy_byimage(real_disp=real_disp, predicted_disp=predicted_disp)\n",
        "\n",
        "\tplt.figure(figsize=(20, 10))\n",
        "\tcolor_map = colors.ListedColormap(['black', 'blue', 'green'])\n",
        "\tplt.imshow(acc, cmap=color_map)\n",
        " \n",
        "#Method which uses real disparity, predicted disparity and pixel error to calcuate accuracy of prediction.\n",
        "#Returns:\n",
        "#        -1 -> if the real disparity is unknown\n",
        "#        0  -> if the prediction in incorrect\n",
        "#        1  -> if the prediction is correct (the prediction must be in the interval which uses allowed pixel error\n",
        "#\n",
        "def disparity_accuracy_byimage(real_disp, predicted_disp, pxl_error=PIXEL_ERROR):\n",
        "\tacc = np.zeros(real_disp.shape)\n",
        "\tacc[real_disp == 0] = -1\n",
        "\tacc[(real_disp != 0) & (np.abs(predicted_disp - real_disp) < pxl_error)] = 1\n",
        "\n",
        "\treturn acc\n",
        "\n",
        "#Method which calculates accuracy percentage, by using real and predicted disparity.\n",
        "def compute_accuracy(model, train=True):\n",
        "\tcounter_correct = 0\n",
        "\tcounter_total = 0\n",
        "\tpxl_error=PIXEL_ERROR\n",
        "\tfor idx in range(TRAIN_START if train else VALID_START,TRAIN_END if train else VALID_END):\n",
        "\t\treal_disp = get_disp_image(idx)\n",
        "\t\tpredicted_disp = compute_disparity_map(idx, model)\n",
        "\t\tcounter_correct += np.count_nonzero((real_disp != 0) & (np.abs(predicted_disp - real_disp) < pxl_error))\n",
        "\t\tcounter_total += np.count_nonzero(real_disp)\n",
        "\n",
        "\treturn counter_correct / counter_total\n",
        "\n",
        "#Method which computes a disparity map of the left and right image\n",
        "def compute_disparity_map(idx, model):\n",
        "      max_disp = MAX_DISP\n",
        "      model.eval()\n",
        "\n",
        "      left_img = get_image(idx, is_left=True)\n",
        "      right_img = get_image(idx, is_left=False)\n",
        "\n",
        "      #Adding the padding, as a result the output image will have the same dimensions as input\n",
        "      padding = PATCH_SIZE // 2\n",
        "      left_pad = np.pad(left_img, ((padding, padding), (padding, padding), (0, 0)))\n",
        "      right_pad = np.pad(right_img, ((padding, padding), (padding, padding), (0, 0)))\n",
        "\n",
        "      left = ToTensor()(left_pad).unsqueeze(0)\n",
        "      right = ToTensor()(right_pad).unsqueeze(0)\n",
        "      left, right = left.to(device), right.to(device)\n",
        "      #Making a ndarray of the tensor, which is the output of the model\n",
        "      left_tensor = model(left)\n",
        "      right_tensor = model(right)\n",
        "\n",
        "      left_array = left_tensor.cpu().squeeze(0).permute(1, 2, 0).detach().numpy()\n",
        "      right_array = right_tensor.cpu().squeeze(0).permute(1, 2, 0).detach().numpy()\n",
        "\n",
        "      #ndarray[HxWxD]\n",
        "      stacked_disp =  np.stack([np.sum(left_array * np.roll(right_array, d, axis=1) , axis=2) for d in range(max_disp)], axis=2)\n",
        "      #ndarray[HxW]-using argmax to extract the most similar\n",
        "      disp_map =  np.argmax(stacked_disp, axis=2)\n",
        "\n",
        "      return disp_map\n",
        "\n",
        "def plot_images(model, idx):\n",
        "    real_disparity = get_disp_image(idx)\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.imshow(real_disparity)\n",
        "    plt.title(f'real disparity {idx}')\n",
        "    predicted_disparity = compute_disparity_map(idx, model)\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.imshow(predicted_disparity)\n",
        "    plt.title(f'predicted disparity {idx}')\n",
        "    plt.show()\n",
        "\n",
        "    plot_acc_byimage(idx, model)\n",
        "    plt.title(f\"accuracy image {idx}\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.imshow(get_image(idx, True))\n",
        "    plt.title(f\"left image {idx}\")\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.imshow(get_image(idx, False))\n",
        "    plt.title(f\"right image {idx}\")\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_model(model):\n",
        "    train_accuracy = compute_accuracy(model, train=True)\n",
        "    test_accuracy = compute_accuracy(model, train=False)\n",
        "    print(f\"train accuracy = {train_accuracy}\\ntest accuracy = {test_accuracy}\")\n",
        "\n",
        "model = torch.load(TRAIN_DATA + f\"train_model_{EPOCHS-1}.pth\")\n",
        "modelGRAY = torch.load(TRAIN_DATA + f\"train_modelGRAY_{EPOCHS-1}.pth\")\n",
        "device = 'cuda'\n",
        "model.to(device)\n",
        "\n",
        "img_idx = 187\n",
        "plot_images(model, img_idx)\n",
        "evaluate_model(model)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "StereoCNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}